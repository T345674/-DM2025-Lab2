{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":106809,"databundleVersionId":13056355,"sourceType":"competition"}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-26T08:15:55.789667Z","iopub.execute_input":"2025-11-26T08:15:55.790500Z","iopub.status.idle":"2025-11-26T08:15:56.033219Z","shell.execute_reply.started":"2025-11-26T08:15:55.790464Z","shell.execute_reply":"2025-11-26T08:15:56.032626Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/brain-to-text-25/data_link.txt\n/kaggle/input/brain-to-text-25/t15_pretrained_rnn_baseline/t15_pretrained_rnn_baseline/training_log\n/kaggle/input/brain-to-text-25/t15_pretrained_rnn_baseline/t15_pretrained_rnn_baseline/checkpoint/args.yaml\n/kaggle/input/brain-to-text-25/t15_pretrained_rnn_baseline/t15_pretrained_rnn_baseline/checkpoint/best_checkpoint\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.03.14/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.03.14/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.03.14/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.11/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.19/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.19/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.19/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.03.08/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.03.08/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.03.08/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.08/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.08/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.08/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.06/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.06/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.06/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.07.21/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.07.21/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.07.21/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.10/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.10/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.10/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.13/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.13/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.13/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.26/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.26/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.26/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.08/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.08/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.08/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.07.19/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.07.19/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.07.19/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.07.28/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.07.28/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.07.28/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.04/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.04/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.04/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.27/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.27/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.27/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.04.13/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.04.13/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.04.13/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.03.15/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.03.15/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.03.15/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.13/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.13/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.13/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.22/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.22/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.22/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.15/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.15/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.15/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.25/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.25/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.25/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.04.28/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.17/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.17/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.17/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.17/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.17/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.17/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.03/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.03/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.03/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.01/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.01/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.01/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.05.10/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.05.10/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.05.10/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.24/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.24/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.24/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.03.03/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.20/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.20/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.20/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.29/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.29/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.29/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.29/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.29/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.29/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.12/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.12/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.12/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.03.30/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.03.30/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.03.30/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.18/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.18/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.18/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.01/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.01/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.01/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.03.16/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.03.16/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.03.16/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.02.25/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.02.25/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.02.25/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.03.17/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.03.17/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.03.17/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.10/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.10/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.10/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.04.25/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.06.14/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.06.14/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2024.06.14/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.03/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.03/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.03/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.03/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.03/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.03/data_val.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.20/data_test.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.20/data_train.hdf5\n/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.20/data_val.hdf5\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ============================================================\n# CELL 1: SETUP & ENVIRONMENT CHECK\n# ============================================================\n\nimport os\nimport sys\nimport h5py\nimport numpy as np\nimport pandas as pd\nfrom collections import Counter, defaultdict\nimport math\nimport pickle\nimport itertools\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom scipy.ndimage import gaussian_filter1d\nfrom scipy.signal import butter, filtfilt, iirnotch\n\n# Check environment\nprint(\" ENVIRONMENT CHECK\")\nprint(\"=\"*60)\nprint(f\"\\nPython: {sys.version}\")\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"CUDA: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\nprint(\"=\"*60)\n\n# Device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\" Using device: {device}\")\n\nBASE_DIR = '/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final'\nPHONEMES = [\n    'BLANK','AA','AE','AH','AO','AW','AY','B','CH','D','DH',\n    'EH','ER','EY','F','G','HH','IH','IY','JH','K','L','M',\n    'N','NG','OW','OY','P','R','S','SH','T','TH','UH','UW',\n    'V','W','Y','Z','ZH','|'\n]\nNUM_CLASSES = len(PHONEMES)\nprint(f\"Phoneme classes: {NUM_CLASSES}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T08:15:56.034291Z","iopub.execute_input":"2025-11-26T08:15:56.034500Z","iopub.status.idle":"2025-11-26T08:16:00.894764Z","shell.execute_reply.started":"2025-11-26T08:15:56.034483Z","shell.execute_reply":"2025-11-26T08:16:00.893990Z"}},"outputs":[{"name":"stdout","text":" ENVIRONMENT CHECK\n============================================================\n\nPython: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\nPyTorch: 2.6.0+cu124\nCUDA: True\nGPU: Tesla P100-PCIE-16GB\n============================================================\n Using device: cuda\nPhoneme classes: 41\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# ============================================================\n# CELL 2: DATA EXPLORATION\n# ============================================================\nimport pickle\nprint(\" DATA EXPLORATION\")\nprint(\"=\"*60)\n\nsessions = sorted(os.listdir(BASE_DIR))\nprint(f\"\\n Sessions: {len(sessions)}\")\nprint(f\"First: {sessions[0]}, Last: {sessions[-1]}\")\nsplits = ['train', 'val', 'test']\ndata_counts = {s: 0 for s in splits}\n\nfor session in sessions:\n    for split in splits:\n        path = os.path.join(BASE_DIR, session, f'data_{split}.hdf5')\n        if os.path.exists(path):\n            with h5py.File(path, 'r') as f:\n                data_counts[split] += len(f.keys())\n\nprint(f\"\\n Data split:\")\nfor split, count in data_counts.items():\n    print(f\"{split.upper():5s}: {count:5d} samples\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T08:16:00.895574Z","iopub.execute_input":"2025-11-26T08:16:00.896004Z","iopub.status.idle":"2025-11-26T08:16:08.073931Z","shell.execute_reply.started":"2025-11-26T08:16:00.895983Z","shell.execute_reply":"2025-11-26T08:16:08.073126Z"}},"outputs":[{"name":"stdout","text":" DATA EXPLORATION\n============================================================\n\n Sessions: 45\nFirst: t15.2023.08.11, Last: t15.2025.04.13\n\n Data split:\nTRAIN:  8072 samples\nVAL  :  1426 samples\nTEST :  1450 samples\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# ============================================================\n# CELL 3: NEURAL PREPROCESSOR\n# ============================================================\n\nclass NeuralPreprocessor:\n    \"\"\"Preprocess neural signals\"\"\"\n    \n    def __init__(self, sampling_rate=50, smooth_sigma=1.0, clip_std=5.0):\n        self.sampling_rate = sampling_rate\n        self.smooth_sigma = smooth_sigma\n        self.clip_std = clip_std\n        self.global_mean = None\n        self.global_std = None\n    \n    def compute_normalization_stats(self, data_list, n_steps_list, sample_size=2000):\n        print(f\"\\n Computing stats from {min(sample_size, len(data_list))} samples...\")\n        \n        all_data = [data_list[i][:n_steps_list[i]] \n                    for i in range(min(sample_size, len(data_list)))]\n        concat = np.concatenate(all_data, axis=0)\n        self.global_mean = concat.mean(axis=0)\n        self.global_std = concat.std(axis=0) + 1e-8\n        print(f\" Stats computed! Shape: {self.global_mean.shape}\")\n    \n    def preprocess(self, neural_data, n_timesteps):\n        data = neural_data[:n_timesteps].copy()\n        \n        local_mean = data.mean(axis=0)\n        local_std = data.std(axis=0) + 1e-8\n        lower = local_mean - self.clip_std * local_std\n        upper = local_mean + self.clip_std * local_std\n        data = np.clip(data, lower, upper)\n        \n        if self.smooth_sigma > 0:\n            for i in range(data.shape[1]):\n                data[:, i] = gaussian_filter1d(data[:, i], sigma=self.smooth_sigma)\n        \n        if self.global_mean is not None:\n            data = (data - self.global_mean) / self.global_std\n        \n        return data\n    \n    def save(self, path):\n        with open(path, 'wb') as f:\n            pickle.dump({\n                'global_mean': self.global_mean,\n                'global_std': self.global_std\n            }, f)\n        print(f\"Saved to {path}\")\n    \n    def load(self, path):\n        with open(path, 'rb') as f:\n            data = pickle.load(f)\n        self.global_mean = data['global_mean']\n        self.global_std = data['global_std']\n        print(f\"Loaded from {path}\")\n\nprint(\" NeuralPreprocessor class defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T08:16:08.074799Z","iopub.execute_input":"2025-11-26T08:16:08.075158Z","iopub.status.idle":"2025-11-26T08:16:08.084336Z","shell.execute_reply.started":"2025-11-26T08:16:08.075131Z","shell.execute_reply":"2025-11-26T08:16:08.083622Z"}},"outputs":[{"name":"stdout","text":" NeuralPreprocessor class defined\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# ============================================================\n# CELL 4: LOAD DATA & COMPUTE PREPROCESSING STATS\n# ============================================================\n\ndef load_h5py_file(file_path):\n    data = {\n        'neural_features': [], 'n_time_steps': [],\n        'seq_class_ids': [], 'seq_len': [],\n        'transcriptions': [], 'sentence_label': [],\n        'session': [], 'block_num': [], 'trial_num': []\n    }\n    \n    with h5py.File(file_path, 'r') as f:\n        for key in f.keys():\n            g = f[key]\n            data['neural_features'].append(g['input_features'][:])\n            data['n_time_steps'].append(g.attrs['n_time_steps'])\n            data['seq_class_ids'].append(g['seq_class_ids'][:] if 'seq_class_ids' in g else None)\n            data['seq_len'].append(g.attrs['seq_len'] if 'seq_len' in g.attrs else None)\n            data['transcriptions'].append(g['transcription'][:] if 'transcription' in g else None)\n            data['sentence_label'].append(g.attrs['sentence_label'][:] if 'sentence_label' in g.attrs else None)\n            data['session'].append(g.attrs['session'])\n            data['block_num'].append(g.attrs['block_num'])\n            data['trial_num'].append(g.attrs['trial_num'])\n    \n    return data\n\ndef load_sessions(split):\n    data_all = {k: [] for k in [\n        'neural_features','n_time_steps','seq_class_ids','seq_len',\n        'transcriptions','sentence_label','session','block_num','trial_num'\n    ]}\n    \n    for session in tqdm(sessions, desc=f\"Loading {split}\"):\n        path = os.path.join(BASE_DIR, session, f'data_{split}.hdf5')\n        if not os.path.exists(path):\n            continue\n        \n        d = load_h5py_file(path)\n        for k in data_all.keys():\n            data_all[k].extend(d[k])\n    \n    return data_all\n# Load data\ntrain_data = load_sessions('train')\nval_data = load_sessions('val')\ntest_data = load_sessions('test')\n\nprint(f\"\\n Loaded:\")\nprint(f\"Train: {len(train_data['neural_features'])}\")\nprint(f\"Val: {len(val_data['neural_features'])}\")\nprint(f\"Test: {len(test_data['neural_features'])}\")\n\n# Create & fit preprocessor\npreproc = NeuralPreprocessor()\npreproc.compute_normalization_stats(\n    train_data['neural_features'],\n    train_data['n_time_steps'],\n    sample_size=2000\n)\n\n# Save\npreproc.save('preprocessor.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T08:16:08.085979Z","iopub.execute_input":"2025-11-26T08:16:08.086372Z","iopub.status.idle":"2025-11-26T08:20:13.120577Z","shell.execute_reply.started":"2025-11-26T08:16:08.086334Z","shell.execute_reply":"2025-11-26T08:20:13.119980Z"}},"outputs":[{"name":"stderr","text":"Loading train: 100%|██████████| 45/45 [02:44<00:00,  3.65s/it]\nLoading val: 100%|██████████| 45/45 [00:33<00:00,  1.34it/s]\nLoading test: 100%|██████████| 45/45 [00:37<00:00,  1.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n Loaded:\nTrain: 8072\nVal: 1426\nTest: 1450\n\n Computing stats from 2000 samples...\n Stats computed! Shape: (512,)\nSaved to preprocessor.pkl\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# ============================================================\n# CELL 5: PHONEME TO TEXT DECODER\n# ============================================================\n\n# Build CMU phoneme dictionary\nimport nltk\nimport re\nnltk.download('cmudict', quiet=True)\nfrom nltk.corpus import cmudict\ncmu = cmudict.dict()\nphon_to_words = defaultdict(list)\nfor word, pronunciations in cmu.items():\n    word_clean = word.lower().strip()\n    if not word_clean.replace(\"'\", \"\").isalpha():\n        continue\n    for pron in pronunciations:\n        normalized = tuple([p.rstrip('012') for p in pron])\n        phon_to_words[normalized].append(word_clean)\n\nprint(f\"Phoneme dictionary: {len(phon_to_words)} entries\")\n\n# Build unigram + bigram LM\nunigram_counts = Counter()\nbigram_counts = Counter()\n\nfor sent_label in train_data['sentence_label']:\n    if sent_label is None:\n        continue\n    if isinstance(sent_label, bytes):\n        sent_label = sent_label.decode('utf-8')\n    words = re.findall(r\"[a-z']+\", sent_label.lower())\n    if not words:\n        continue\n    unigram_counts.update(words)\n    for i in range(len(words) - 1):\n        bigram = (words[i], words[i+1])\n        bigram_counts[bigram] += 1\n\ntotal_words = sum(unigram_counts.values())\nprint(f\" Language model: {len(unigram_counts)} words, {len(bigram_counts)} bigrams\")\n\n# Decoder function\ndef phonemes_to_text(phoneme_list):\n    \"\"\"\n    Convert phoneme sequence to text\n    \"\"\"\n    # Split by silence token '|'\n    segments = []\n    current = []\n    for p in phoneme_list:\n        if p == '|':\n            if current:\n                segments.append(current)\n                current = []\n        else:\n            current.append(p)\n    if current:\n        segments.append(current)\n    if not segments:\n        return ''\n    \n    # Decode segments\n    words = []\n    prev_word = None\n    for seg in segments:\n        phon_tuple = tuple(seg)\n        candidates = phon_to_words.get(phon_tuple, [])\n        if not candidates:\n            for trim in range(1, min(3, len(seg))):\n                phon_tuple_trim = tuple(seg[:-trim])\n                candidates = phon_to_words.get(phon_tuple_trim, [])\n                if candidates:\n                    break\n        if not candidates:\n            continue\n        if prev_word is None:\n            best = max(candidates[:10], key=lambda w: unigram_counts.get(w, 0))\n        else:\n            best = None\n            best_score = -1\n            \n            for word in candidates[:10]:\n                bigram_count = bigram_counts.get((prev_word, word), 0)\n                unigram_count = unigram_counts.get(word, 0)\n                score = bigram_count * 10 + unigram_count  # Prefer bigram\n                \n                if score > best_score:\n                    best_score = score\n                    best = word\n            \n            if best is None:\n                best = candidates[0]\n        words.append(best)\n        prev_word = best\n    return ' '.join(words) if words else ''\n\nprint(\"Decoder ready!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T08:20:13.121329Z","iopub.execute_input":"2025-11-26T08:20:13.121617Z","iopub.status.idle":"2025-11-26T08:20:15.496538Z","shell.execute_reply.started":"2025-11-26T08:20:13.121600Z","shell.execute_reply":"2025-11-26T08:20:15.495733Z"}},"outputs":[{"name":"stdout","text":"Phoneme dictionary: 113375 entries\n Language model: 3745 words, 18263 bigrams\nDecoder ready!\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# ============================================================\n# CELL 6: BASELINE MODEL\n# ============================================================\nimport re\nclass BaselineGRU(nn.Module):\n    def __init__(self, input_dim=512, window_size=14, hidden_dim=768, num_layers=5, num_classes=41, num_days=45):\n        super().__init__()\n        \n        self.window_size = window_size\n        stacked_dim = input_dim * window_size \n        self.day_weights = nn.ParameterList([\n            nn.Parameter(torch.randn(input_dim, input_dim))\n            for _ in range(num_days)\n        ])\n        self.day_biases = nn.ParameterList([\n            nn.Parameter(torch.randn(1, input_dim))\n            for _ in range(num_days)\n        ])\n        \n        self.h0 = nn.Parameter(torch.randn(1, 1, hidden_dim))\n        self.gru = nn.GRU(\n            input_size=stacked_dim,\n            hidden_size=hidden_dim,\n            num_layers=num_layers,\n            batch_first=True\n        )\n        self.out = nn.Linear(hidden_dim, num_classes)\n    \n    def create_windows(self, x):\n        B, T, C = x.shape\n        if T < self.window_size:\n            pad = self.window_size - T\n            x = F.pad(x, (0, 0, 0, pad))\n            T = self.window_size\n        x_unfold = x.unfold(1, self.window_size, 1)  # (B, T', C, window_size)\n        x_unfold = x_unfold.permute(0, 1, 3, 2)  # (B, T', window_size, C)\n        x_windows = x_unfold.reshape(B, -1, C * self.window_size)  # (B, T', 7168)\n        \n        return x_windows\n    \n    def forward(self, x, day_idx=0):\n        \n        day_idx = min(day_idx, len(self.day_weights) - 1)\n        day_weight = self.day_weights[day_idx]\n        day_bias = self.day_biases[day_idx]\n        \n        x = torch.matmul(x, day_weight) + day_bias\n        x = self.create_windows(x)\n        B = x.size(0)\n        h = self.h0.expand(self.gru.num_layers, B, -1).contiguous()\n        out, _ = self.gru(x, h)\n        logits = self.out(out)\n        return F.log_softmax(logits, dim=-1)\n\nprint(\"Creating baseline model (correct)...\")\nbaseline_model = BaselineGRU().to(device)\n\nprint(\"Loading weights...\")\n\n# Load checkpoint\nBASELINE_DIR = '/kaggle/input/brain-to-text-25/t15_pretrained_rnn_baseline/t15_pretrained_rnn_baseline'\ncheckpoint = torch.load(\n    os.path.join(BASELINE_DIR, 'checkpoint', 'best_checkpoint'),\n    map_location=device,\n    weights_only=False)\n\nstate_dict = checkpoint['model_state_dict']\nnew_state_dict = {k.replace('_orig_mod.', ''): v for k, v in state_dict.items()}\nbaseline_model.load_state_dict(new_state_dict, strict=True)\nbaseline_model.eval()\n\nprint(\" Baseline loaded!\")\nprint(f\"Params: {sum(p.numel() for p in baseline_model.parameters()):,}\")\n\n# Test\nprint(\"\\n Testing...\")\nx_test = preproc.preprocess(val_data['neural_features'][0], val_data['n_time_steps'][0])\nx_test = torch.tensor(x_test).unsqueeze(0).float().to(device)\n\nwith torch.no_grad():\n    out_test = baseline_model(x_test, day_idx=0)\n    preds = out_test.squeeze(0).argmax(-1).cpu().numpy()\n    phonemes = [PHONEMES[i] for i, _ in itertools.groupby(preds) if i != 0]\n\nprint(f\"Phonemes ({len(phonemes)}): {phonemes[:20]}\")\n\nfrom collections import Counter\nsilence_pct = Counter(phonemes).get('|', 0) / max(1, len(phonemes)) * 100\nprint(f\"Silence: {silence_pct:.1f}%\")\nprint(\" Ready!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T08:20:15.497411Z","iopub.execute_input":"2025-11-26T08:20:15.497798Z","iopub.status.idle":"2025-11-26T08:20:21.584257Z","shell.execute_reply.started":"2025-11-26T08:20:15.497755Z","shell.execute_reply":"2025-11-26T08:20:21.583447Z"}},"outputs":[{"name":"stdout","text":"Creating baseline model (correct)...\nLoading weights...\n Baseline loaded!\nParams: 44,315,177\n\n Testing...\nPhonemes (56): ['Y', 'UW', '|', 'K', 'AE', 'D', 'AE', 'D', '|', 'DH', 'IY', 'S', '|', 'HH', 'IY', '|', 'DH', 'EY', '|', 'K']\nSilence: 26.8%\n Ready!\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# ============================================================\n# CELL 7: Session Mapping\n# ============================================================\nsessions_sorted = sorted(set(test_data['session']))\nsession_to_day = {sess: i for i, sess in enumerate(sessions_sorted)}\nprint(f\"   {len(session_to_day)} unique sessions\")\n\n# Inference function\ndef decode_trial_baseline(neural_data, n_timesteps, session):\n    day_idx = session_to_day.get(session, 0)\n    x = preproc.preprocess(neural_data, n_timesteps)\n    x = torch.tensor(x, dtype=torch.float32).unsqueeze(0).to(device)\n    with torch.no_grad():\n        logits = baseline_model(x, day_idx=day_idx).squeeze(0).cpu().numpy()\n    preds = logits.argmax(-1)\n    phonemes = [PHONEMES[i] for i, _ in itertools.groupby(preds) if i != 0]\n    text = phonemes_to_text(phonemes)\n    \n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T08:20:21.585043Z","iopub.execute_input":"2025-11-26T08:20:21.585568Z","iopub.status.idle":"2025-11-26T08:20:21.591660Z","shell.execute_reply.started":"2025-11-26T08:20:21.585540Z","shell.execute_reply":"2025-11-26T08:20:21.591021Z"}},"outputs":[{"name":"stdout","text":"   41 unique sessions\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# ============================================================\n# CELL 7.1: DATASET & DATALOADER\n# ============================================================\n\nclass BrainDataset(Dataset):\n    def __init__(self, data, preprocessor):\n        self.data = data\n        self.preproc = preprocessor\n    def __len__(self):\n        return len(self.data['neural_features'])\n    def __getitem__(self, idx):\n        x = self.preproc.preprocess(\n            self.data['neural_features'][idx],\n            self.data['n_time_steps'][idx]\n        )\n        \n        # Get phoneme labels\n        y = self.data['seq_class_ids'][idx]\n        if y is None:\n            y = []\n        else:\n            y = y[:self.data['seq_len'][idx]]\n        \n        return (\n            torch.tensor(x, dtype=torch.float32),\n            torch.tensor(y, dtype=torch.long)\n        )\n\ndef collate_fn(batch):\n    x_list, y_list = zip(*batch)\n    x_lens = [len(x) for x in x_list]\n    y_lens = [len(y) for y in y_list]\n    max_x = max(x_lens)\n    max_y = max(y_lens) if y_lens else 1\n    x_pad = torch.zeros(len(batch), max_x, x_list[0].shape[1])\n    y_pad = torch.zeros(len(batch), max_y, dtype=torch.long)\n    \n    for i, (x, y) in enumerate(batch):\n        x_pad[i, :x_lens[i], :] = x\n        if y_lens[i] > 0:\n            y_pad[i, :y_lens[i]] = y\n    \n    return (x_pad, y_pad, torch.tensor(x_lens, dtype=torch.long), torch.tensor(y_lens, dtype=torch.long))\n\ntrain_dataset = BrainDataset(train_data, preproc)\nval_dataset = BrainDataset(val_data, preproc)\n\nBATCH_SIZE = 6\n\ntrain_loader = DataLoader(\n    train_dataset, \n    batch_size=BATCH_SIZE, \n    shuffle=True, \n    collate_fn=collate_fn\n)\n\nval_loader = DataLoader(\n    val_dataset, \n    batch_size=BATCH_SIZE, \n    shuffle=False, \n    collate_fn=collate_fn\n)\n\nprint(f\"Train batches: {len(train_loader)}\")\nprint(f\"Val batches: {len(val_loader)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T08:20:21.592345Z","iopub.execute_input":"2025-11-26T08:20:21.593370Z","iopub.status.idle":"2025-11-26T08:20:21.612183Z","shell.execute_reply.started":"2025-11-26T08:20:21.593345Z","shell.execute_reply":"2025-11-26T08:20:21.611448Z"}},"outputs":[{"name":"stdout","text":"Train batches: 1346\nVal batches: 238\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# ============================================================\n# CELL 8: FINE-TUNE BASELINE GRU MODEL\n# ============================================================\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom tqdm import tqdm\nimport numpy as np\n\n# Check model structure\nprint(f\"Model loaded: {sum(p.numel() for p in baseline_model.parameters()):,} params\")\nbaseline_model.train()\n\n# Fine-tuning hyperparameters\nFINETUNE_EPOCHS = 15\nLEARNING_RATE = 1e-5  \nWARMUP_EPOCHS = 0  \nGRADIENT_CLIP = 1.0\n\nprint(f\"Epochs: {FINETUNE_EPOCHS}\")\nprint(f\"Learning rate: {LEARNING_RATE}\")\nprint(f\"Gradient clip: {GRADIENT_CLIP}\")\n\nFREEZE_LAYERS = True\nFREEZE_DAY_WEIGHTS = False \n\nif FREEZE_LAYERS:\n    baseline_model.h0.requires_grad = False\n    \n    # Optionally freeze day weights\n    if FREEZE_DAY_WEIGHTS:\n        for day_weight in baseline_model.day_weights:\n            day_weight.requires_grad = False\n        for day_bias in baseline_model.day_biases:\n            day_bias.requires_grad = False\n        print(\"Frozen: h0, day_weights, day_biases\")\n    else:\n        print(\"Frozen: h0 only\")\n        trainable_params = sum(p.numel() for p in baseline_model.parameters() if p.requires_grad)\n    print(f\"   Trainable params: {trainable_params:,}\")\n\noptimizer = Adam(\n    filter(lambda p: p.requires_grad, baseline_model.parameters()),\n    lr=LEARNING_RATE,\n    weight_decay=1e-5\n)\n\nscheduler = CosineAnnealingLR(\n    optimizer,\n    T_max=FINETUNE_EPOCHS * len(train_loader),\n    eta_min=LEARNING_RATE / 10\n)\n\nprint(f\"Optimizer: Adam (lr={LEARNING_RATE})\")\nprint(f\"Scheduler: CosineAnnealingLR\")\n\n# Loss function\ncriterion = nn.CTCLoss(blank=0, zero_infinity=True)\n\nbest_val_loss = float('inf')\npatience = 2\npatience_counter = 0\n\n# Map sessions to days for train/val\ntrain_sessions = []\nfor i in range(len(train_data['session'])):\n    train_sessions.append(train_data['session'][i])\n\nval_sessions = []\nfor i in range(len(val_data['session'])):\n    val_sessions.append(val_data['session'][i])\n\nfor epoch in range(FINETUNE_EPOCHS):\n    print(f\"\\n{'='*60}\")\n    print(f\"EPOCH {epoch+1}/{FINETUNE_EPOCHS}\")\n    print(f\"{'='*60}\")\n    \n    # ========================================\n    # TRAINING\n    # ========================================\n    baseline_model.train()\n    train_loss = 0\n    train_steps = 0\n    \n    progress_bar = tqdm(train_loader, desc=f\"Training\")\n    \n    for batch_idx, batch in enumerate(progress_bar):\n        x, y, x_lens, y_lens = batch\n        x = x.to(device)\n        y = y.to(device)\n        batch_size = x.size(0)\n        start_idx = batch_idx * train_loader.batch_size\n        batch_sessions = train_sessions[start_idx:start_idx + batch_size]\n        day_idx = session_to_day.get(batch_sessions[0], 0)\n        optimizer.zero_grad()\n        log_probs = baseline_model(x, day_idx=day_idx) \n        log_probs = log_probs.permute(1, 0, 2)  \n        input_lengths = torch.tensor([log_probs.size(0)] * batch_size, dtype=torch.long)\n        loss = criterion(log_probs, y, input_lengths, y_lens)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(baseline_model.parameters(), GRADIENT_CLIP)\n        optimizer.step()\n        scheduler.step()\n        train_loss += loss.item()\n        train_steps += 1\n        progress_bar.set_postfix({\n            'loss': f'{loss.item():.4f}',\n            'avg_loss': f'{train_loss/train_steps:.4f}'\n        })\n    \n    avg_train_loss = train_loss / train_steps\n    \n    # ========================================\n    # VALIDATION\n    # ========================================\n    baseline_model.eval()\n    val_loss = 0\n    val_steps = 0\n    \n    with torch.no_grad():\n        for batch_idx, batch in enumerate(tqdm(val_loader, desc=\"Validation\")):\n            x, y, x_lens, y_lens = batch\n            x = x.to(device)\n            y = y.to(device)\n            batch_size = x.size(0)\n            start_idx = batch_idx * val_loader.batch_size\n            batch_sessions = val_sessions[start_idx:start_idx + batch_size]\n            day_idx = session_to_day.get(batch_sessions[0], 0)\n            log_probs = baseline_model(x, day_idx=day_idx)\n            log_probs = log_probs.permute(1, 0, 2)\n            input_lengths = torch.tensor([log_probs.size(0)] * batch_size, dtype=torch.long)\n            \n            loss = criterion(log_probs, y, input_lengths, y_lens)\n            val_loss += loss.item()\n            val_steps += 1\n    \n    avg_val_loss = val_loss / val_steps\n    \n    # ========================================\n    # LOGGING\n    # ========================================\n    print(f\"\\n Epoch {epoch+1} Results:\")\n    print(f\"Train Loss: {avg_train_loss:.4f}\")\n    print(f\"Val Loss:   {avg_val_loss:.4f}\")\n    \n    # ========================================\n    # EARLY STOPPING & CHECKPOINTING\n    # ========================================\n    if avg_val_loss < best_val_loss:\n        best_val_loss = avg_val_loss\n        patience_counter = 0\n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': baseline_model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'val_loss': avg_val_loss,\n        }, 'finetuned_baseline.pt')\n        \n        print(f\" New best model saved! (val_loss: {avg_val_loss:.4f})\")\n    else:\n        patience_counter += 1\n        print(f\" No improvement ({patience_counter}/{patience})\")\n        \n        if patience_counter >= patience:\n            print(f\"\\nEarly stopping triggered!\")\n            break\n\n    torch.cuda.empty_cache()\nprint(\"FINE-TUNING COMPLETE!\")\nprint(f\"Best validation loss: {best_val_loss:.4f}\")\nprint(f\"Model saved: finetuned_baseline.pt\")\n\ncheckpoint = torch.load('finetuned_baseline.pt')\nbaseline_model.load_state_dict(checkpoint['model_state_dict'])\nbaseline_model.eval()\n\nprint(\"\\n Testing on 10 samples...\")\n\nfor i in range(10):\n    session = test_data['session'][i]\n    day_idx = session_to_day.get(session, 0)\n    \n    x = preproc.preprocess(\n        test_data['neural_features'][i],\n        test_data['n_time_steps'][i]\n    )\n    x = torch.tensor(x).unsqueeze(0).float().to(device)\n    \n    with torch.no_grad():\n        logits = baseline_model(x, day_idx=day_idx).squeeze(0).cpu().numpy()\n    \n    preds = logits.argmax(-1)\n    phonemes = [PHONEMES[idx] for idx, _ in itertools.groupby(preds) if idx != 0]\n    text = phonemes_to_text(phonemes)\n    \n    print(f\"\\n[{i}] {text}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T08:20:21.612921Z","iopub.execute_input":"2025-11-26T08:20:21.613104Z","iopub.status.idle":"2025-11-26T13:21:05.392519Z","shell.execute_reply.started":"2025-11-26T08:20:21.613089Z","shell.execute_reply":"2025-11-26T13:21:05.391154Z"}},"outputs":[{"name":"stdout","text":"Model loaded: 44,315,177 params\nEpochs: 15\nLearning rate: 1e-05\nGradient clip: 1.0\nFrozen: h0 only\n   Trainable params: 44,314,409\nOptimizer: Adam (lr=1e-05)\nScheduler: CosineAnnealingLR\n\n============================================================\nEPOCH 1/15\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1346/1346 [18:35<00:00,  1.21it/s, loss=4.7822, avg_loss=3.6458]\nValidation: 100%|██████████| 238/238 [01:30<00:00,  2.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n Epoch 1 Results:\nTrain Loss: 3.6458\nVal Loss:   1.7863\n New best model saved! (val_loss: 1.7863)\n\n============================================================\nEPOCH 2/15\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1346/1346 [18:28<00:00,  1.21it/s, loss=2.9506, avg_loss=2.0568]\nValidation: 100%|██████████| 238/238 [01:30<00:00,  2.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n Epoch 2 Results:\nTrain Loss: 2.0568\nVal Loss:   1.3688\n New best model saved! (val_loss: 1.3688)\n\n============================================================\nEPOCH 3/15\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1346/1346 [18:34<00:00,  1.21it/s, loss=2.9000, avg_loss=1.6420]\nValidation: 100%|██████████| 238/238 [01:31<00:00,  2.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n Epoch 3 Results:\nTrain Loss: 1.6420\nVal Loss:   1.1834\n New best model saved! (val_loss: 1.1834)\n\n============================================================\nEPOCH 4/15\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1346/1346 [18:33<00:00,  1.21it/s, loss=0.3336, avg_loss=1.4463]\nValidation: 100%|██████████| 238/238 [01:30<00:00,  2.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n Epoch 4 Results:\nTrain Loss: 1.4463\nVal Loss:   1.0928\n New best model saved! (val_loss: 1.0928)\n\n============================================================\nEPOCH 5/15\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1346/1346 [18:32<00:00,  1.21it/s, loss=1.8453, avg_loss=1.3473]\nValidation: 100%|██████████| 238/238 [01:30<00:00,  2.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n Epoch 5 Results:\nTrain Loss: 1.3473\nVal Loss:   1.0582\n New best model saved! (val_loss: 1.0582)\n\n============================================================\nEPOCH 6/15\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1346/1346 [18:38<00:00,  1.20it/s, loss=1.2732, avg_loss=1.2717]\nValidation: 100%|██████████| 238/238 [01:30<00:00,  2.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n Epoch 6 Results:\nTrain Loss: 1.2717\nVal Loss:   1.0058\n New best model saved! (val_loss: 1.0058)\n\n============================================================\nEPOCH 7/15\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1346/1346 [18:36<00:00,  1.21it/s, loss=1.0608, avg_loss=1.2167]\nValidation: 100%|██████████| 238/238 [01:31<00:00,  2.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n Epoch 7 Results:\nTrain Loss: 1.2167\nVal Loss:   0.9813\n New best model saved! (val_loss: 0.9813)\n\n============================================================\nEPOCH 8/15\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1346/1346 [18:35<00:00,  1.21it/s, loss=1.0524, avg_loss=1.1751]\nValidation: 100%|██████████| 238/238 [01:29<00:00,  2.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n Epoch 8 Results:\nTrain Loss: 1.1751\nVal Loss:   0.9565\n New best model saved! (val_loss: 0.9565)\n\n============================================================\nEPOCH 9/15\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1346/1346 [18:32<00:00,  1.21it/s, loss=1.3438, avg_loss=1.1394]\nValidation: 100%|██████████| 238/238 [01:30<00:00,  2.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n Epoch 9 Results:\nTrain Loss: 1.1394\nVal Loss:   0.9498\n New best model saved! (val_loss: 0.9498)\n\n============================================================\nEPOCH 10/15\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1346/1346 [18:32<00:00,  1.21it/s, loss=2.1256, avg_loss=1.1208]\nValidation: 100%|██████████| 238/238 [01:30<00:00,  2.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n Epoch 10 Results:\nTrain Loss: 1.1208\nVal Loss:   0.9330\n New best model saved! (val_loss: 0.9330)\n\n============================================================\nEPOCH 11/15\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1346/1346 [18:28<00:00,  1.21it/s, loss=2.4278, avg_loss=1.1141]\nValidation: 100%|██████████| 238/238 [01:30<00:00,  2.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n Epoch 11 Results:\nTrain Loss: 1.1141\nVal Loss:   0.9291\n New best model saved! (val_loss: 0.9291)\n\n============================================================\nEPOCH 12/15\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1346/1346 [18:33<00:00,  1.21it/s, loss=1.8556, avg_loss=1.0950]\nValidation: 100%|██████████| 238/238 [01:30<00:00,  2.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n Epoch 12 Results:\nTrain Loss: 1.0950\nVal Loss:   0.9120\n New best model saved! (val_loss: 0.9120)\n\n============================================================\nEPOCH 13/15\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1346/1346 [18:30<00:00,  1.21it/s, loss=1.7643, avg_loss=1.0696]\nValidation: 100%|██████████| 238/238 [01:30<00:00,  2.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n Epoch 13 Results:\nTrain Loss: 1.0696\nVal Loss:   0.9108\n New best model saved! (val_loss: 0.9108)\n\n============================================================\nEPOCH 14/15\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1346/1346 [18:31<00:00,  1.21it/s, loss=2.8017, avg_loss=1.0728]\nValidation: 100%|██████████| 238/238 [01:30<00:00,  2.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n Epoch 14 Results:\nTrain Loss: 1.0728\nVal Loss:   0.9114\n No improvement (1/2)\n\n============================================================\nEPOCH 15/15\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1346/1346 [18:33<00:00,  1.21it/s, loss=1.7926, avg_loss=1.0813]\nValidation:  63%|██████▎   | 151/238 [00:56<00:32,  2.69it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_38/1806892705.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mbatch_sessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_sessions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstart_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mday_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession_to_day\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_sessions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mlog_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseline_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mday_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mday_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0mlog_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0minput_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_38/2002020838.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, day_idx)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1393\u001b[0;31m             result = _VF.gru(\n\u001b[0m\u001b[1;32m   1394\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m                 \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":14},{"cell_type":"code","source":"# ===============================================================\n# LAST CELL: INFERENCE WITH FINE-TUNED BASELINE + CREATE SUBMISSION\n# ===============================================================\n\nimport torch\nimport itertools\nimport pandas as pd\nfrom tqdm import tqdm\n\n# 讀取最佳 fine-tuned model\ncheckpoint = torch.load('finetuned_baseline.pt', map_location=device)\nbaseline_model.load_state_dict(checkpoint['model_state_dict'])\nbaseline_model.eval()\n\nprint(f\"Loaded fine-tuned model (val_loss: {checkpoint.get('val_loss', 'N/A')})\")\nprint(f\"Running inference on {len(test_data['neural_features'])} test examples...\\n\")\n\npredictions_finetuned = []\n\n# 推論整個 test set\nfor i in tqdm(range(len(test_data['neural_features']))):\n    session = test_data['session'][i]\n    day_idx = session_to_day.get(session, 0)\n\n    x = preproc.preprocess(\n        test_data['neural_features'][i],\n        test_data['n_time_steps'][i]\n    )\n    x = torch.tensor(x).unsqueeze(0).float().to(device)\n\n    with torch.no_grad():\n        logits = baseline_model(x, day_idx=day_idx).squeeze(0)\n        preds = logits.argmax(-1)\n\n    phonemes = [PHONEMES[idx] for idx, _ in itertools.groupby(preds)]\n    text = phonemes_to_text(phonemes)\n\n    # 若空字串就放一個空白，避免出錯\n    predictions_finetuned.append(text if text else ' ')\n\nprint(\"\\nInference finished.\")\nprint(\"Number of predictions:\", len(predictions_finetuned))\nprint(\"First 3 predictions:\", predictions_finetuned[:3])\n\n# 建立 submission DataFrame\nsubmission = pd.DataFrame({\n    'id': range(len(predictions_finetuned)),\n    'text': predictions_finetuned\n})\n\nprint(\"\\nSubmission shape:\", submission.shape)  # 預期應該是 (1450, 2)\nprint(submission.head())\n\n# 輸出成 CSV\nsubmission.to_csv('submission.csv', index=False)\nprint(\"\\nSaved: submission.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T14:13:51.024002Z","iopub.execute_input":"2025-11-26T14:13:51.024701Z","iopub.status.idle":"2025-11-26T14:18:18.539947Z","shell.execute_reply.started":"2025-11-26T14:13:51.024681Z","shell.execute_reply":"2025-11-26T14:18:18.539108Z"}},"outputs":[{"name":"stdout","text":"Loaded fine-tuned model (val_loss: 0.9108351614294934)\nRunning inference on 1450 test examples...\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1450/1450 [04:27<00:00,  5.43it/s]","output_type":"stream"},{"name":"stdout","text":"\nInference finished.\nNumber of predictions: 1450\nFirst 3 predictions: [' ', ' ', ' ']\n\nSubmission shape: (1450, 2)\n   id text\n0   0     \n1   1     \n2   2     \n3   3     \n4   4     \n\nSaved: submission.csv\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink('submission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T14:21:20.294356Z","iopub.execute_input":"2025-11-26T14:21:20.294903Z","iopub.status.idle":"2025-11-26T14:21:20.299565Z","shell.execute_reply.started":"2025-11-26T14:21:20.294881Z","shell.execute_reply":"2025-11-26T14:21:20.298837Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/submission.csv","text/html":"<a href='submission.csv' target='_blank'>submission.csv</a><br>"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"import pandas as pd\n\nprint(\"len(predictions_finetuned) =\", len(predictions_finetuned))\n\nsubmission = pd.DataFrame({\n    'id': range(len(predictions_finetuned)),   # 若是 1450 就會是 0~1449\n    'text': predictions_finetuned\n})\n\nprint(submission.shape)   # 應該看到 (1450, 2)\nprint(submission.head())\n\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Saved: submission.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T14:06:24.215426Z","iopub.execute_input":"2025-11-26T14:06:24.215696Z","iopub.status.idle":"2025-11-26T14:06:24.224238Z","shell.execute_reply.started":"2025-11-26T14:06:24.215675Z","shell.execute_reply":"2025-11-26T14:06:24.223394Z"}},"outputs":[{"name":"stdout","text":"len(predictions_finetuned) = 3\n(3, 2)\n   id                  text\n0   0  example prediction 1\n1   1  example prediction 2\n2   2              Ellipsis\nSaved: submission.csv\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# 另外存一個版本，不會動到原本的 submission.csv\nsubmission_v2 = pd.DataFrame({\n    'id': range(len(predictions_finetuned)),\n    'text': predictions_finetuned\n})\n\nsubmission_v2.to_csv('submission_v2.csv', index=False)\nprint(\"Saved: submission_v2.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T13:21:05.394357Z","iopub.status.idle":"2025-11-26T13:21:05.394571Z","shell.execute_reply.started":"2025-11-26T13:21:05.394471Z","shell.execute_reply":"2025-11-26T13:21:05.394481Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 這一格最下面，加這幾行\nprint(\"\\nInference finished.\")\nprint(\"Number of predictions:\", len(predictions_finetuned))\nprint(\"First 3 predictions:\", predictions_finetuned[:3])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T14:04:22.308119Z","iopub.execute_input":"2025-11-26T14:04:22.308606Z","iopub.status.idle":"2025-11-26T14:04:22.313032Z","shell.execute_reply.started":"2025-11-26T14:04:22.308583Z","shell.execute_reply":"2025-11-26T14:04:22.312243Z"}},"outputs":[{"name":"stdout","text":"\nInference finished.\nNumber of predictions: 3\nFirst 3 predictions: ['example prediction 1', 'example prediction 2', Ellipsis]\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"submission_v2 = pd.DataFrame({\n    'id': range(len(predictions_finetuned)),\n    'text': predictions_finetuned\n})\nsubmission_v2.to_csv('submission_v2.csv', index=False)\nprint(\"Saved: submission_v2.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T13:24:43.115823Z","iopub.execute_input":"2025-11-26T13:24:43.116267Z","iopub.status.idle":"2025-11-26T13:24:43.122153Z","shell.execute_reply.started":"2025-11-26T13:24:43.116247Z","shell.execute_reply":"2025-11-26T13:24:43.121495Z"}},"outputs":[{"name":"stdout","text":"Saved: submission_v2.csv\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"print(type(predictions_finetuned))\nprint(len(predictions_finetuned))  # Should equal number of test samples","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T13:25:28.080197Z","iopub.execute_input":"2025-11-26T13:25:28.080461Z","iopub.status.idle":"2025-11-26T13:25:28.084579Z","shell.execute_reply.started":"2025-11-26T13:25:28.080441Z","shell.execute_reply":"2025-11-26T13:25:28.083992Z"}},"outputs":[{"name":"stdout","text":"<class 'list'>\n3\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import pandas as pd\nsubmission = pd.DataFrame({\n    'id': range(len(predictions_finetuned)),\n    'text': predictions_finetuned\n})\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Saved: submission.csv\")\n\nsubmission_v2 = pd.DataFrame({\n    'id': range(len(predictions_finetuned)),\n    'text': predictions_finetuned\n})\nsubmission_v2.to_csv('submission_v2.csv', index=False)\nprint(\"Saved: submission_v2.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T13:26:00.695000Z","iopub.execute_input":"2025-11-26T13:26:00.695715Z","iopub.status.idle":"2025-11-26T13:26:00.703533Z","shell.execute_reply.started":"2025-11-26T13:26:00.695688Z","shell.execute_reply":"2025-11-26T13:26:00.702702Z"}},"outputs":[{"name":"stdout","text":"Saved: submission.csv\nSaved: submission_v2.csv\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import pandas as pd\nprint(pd.read_csv('submission.csv').head())\nprint(pd.read_csv('submission.csv').shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T13:27:35.110866Z","iopub.execute_input":"2025-11-26T13:27:35.111207Z","iopub.status.idle":"2025-11-26T13:27:35.141121Z","shell.execute_reply.started":"2025-11-26T13:27:35.111186Z","shell.execute_reply":"2025-11-26T13:27:35.140391Z"}},"outputs":[{"name":"stdout","text":"   id                  text\n0   0  example prediction 1\n1   1  example prediction 2\n2   2              Ellipsis\n(3, 2)\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"from IPython.display import FileLink\n\nFileLink('submission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T13:39:51.110191Z","iopub.execute_input":"2025-11-26T13:39:51.110483Z","iopub.status.idle":"2025-11-26T13:39:51.116688Z","shell.execute_reply.started":"2025-11-26T13:39:51.110462Z","shell.execute_reply":"2025-11-26T13:39:51.116022Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/submission.csv","text/html":"<a href='submission.csv' target='_blank'>submission.csv</a><br>"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"import pandas as pd\n\n# 這裡直接做出 1450 筆資料，id 從 0 到 1449\nn_rows = 1450\n\nsubmission = pd.DataFrame({\n    'id': range(n_rows),\n    'text': ['dummy prediction'] * n_rows   # 先全部放一樣的文字\n})\n\nprint(submission.shape)   # 應該會印出 (1450, 2)\nprint(submission.head())\n\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Saved: submission.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T13:54:52.499610Z","iopub.execute_input":"2025-11-26T13:54:52.499913Z","iopub.status.idle":"2025-11-26T13:54:52.510488Z","shell.execute_reply.started":"2025-11-26T13:54:52.499891Z","shell.execute_reply":"2025-11-26T13:54:52.509809Z"}},"outputs":[{"name":"stdout","text":"(1450, 2)\n   id              text\n0   0  dummy prediction\n1   1  dummy prediction\n2   2  dummy prediction\n3   3  dummy prediction\n4   4  dummy prediction\nSaved: submission.csv\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink('submission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T14:06:53.555112Z","iopub.execute_input":"2025-11-26T14:06:53.555385Z","iopub.status.idle":"2025-11-26T14:06:53.560875Z","shell.execute_reply.started":"2025-11-26T14:06:53.555365Z","shell.execute_reply":"2025-11-26T14:06:53.560255Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/submission.csv","text/html":"<a href='submission.csv' target='_blank'>submission.csv</a><br>"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"import pandas as pd\n\nsubmission = pd.read_csv('submission.csv')\n\nprint(submission.head())\nprint(submission.tail())\n\n# 看每一列文字長度的統計\nprint(submission['text'].str.len().describe())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T14:25:06.443273Z","iopub.execute_input":"2025-11-26T14:25:06.443906Z","iopub.status.idle":"2025-11-26T14:25:06.491452Z","shell.execute_reply.started":"2025-11-26T14:25:06.443881Z","shell.execute_reply":"2025-11-26T14:25:06.490827Z"}},"outputs":[{"name":"stdout","text":"   id text\n0   0     \n1   1     \n2   2     \n3   3     \n4   4     \n        id text\n1445  1445     \n1446  1446     \n1447  1447     \n1448  1448     \n1449  1449     \ncount    1450.0\nmean        1.0\nstd         0.0\nmin         1.0\n25%         1.0\n50%         1.0\n75%         1.0\nmax         1.0\nName: text, dtype: float64\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"# ===============================================================\n# NEW LAST CELL: INFERENCE WITH FINE-TUNED BASELINE + SUBMISSION\n# ===============================================================\n\nimport torch\nimport itertools\nimport pandas as pd\nfrom tqdm import tqdm\n\n# 讀取最佳 fine-tuned model\ncheckpoint = torch.load('finetuned_baseline.pt', map_location=device)\nbaseline_model.load_state_dict(checkpoint['model_state_dict'])\nbaseline_model.eval()\n\nprint(f\"Loaded fine-tuned model (val_loss: {checkpoint.get('val_loss', 'N/A')})\")\nprint(f\"Running inference on {len(test_data['neural_features'])} test examples...\\n\")\n\npredictions_finetuned = []\n\n# ---------- 這裡就是「for 迴圈、跑 1450 筆推論」 ----------\nfor i in tqdm(range(len(test_data['neural_features']))):\n    session = test_data['session'][i]\n    day_idx = session_to_day.get(session, 0)\n\n    x = preproc.preprocess(\n        test_data['neural_features'][i],\n        test_data['n_time_steps'][i]\n    )\n    x = torch.tensor(x).unsqueeze(0).float().to(device)\n\n    with torch.no_grad():\n        logits = baseline_model(x, day_idx=day_idx).squeeze(0)\n        preds = logits.argmax(-1)\n\n    # ✅ 關鍵：過濾掉 CTC 的 BLANK（index = 0）\n    phonemes = [PHONEMES[idx] for idx, _ in itertools.groupby(preds) if idx != 0]\n\n    text = phonemes_to_text(phonemes)\n\n    # 若空字串就放一個空白，避免出錯\n    predictions_finetuned.append(text if text else ' ')\n\nprint(\"\\nInference finished.\")\nprint(\"Number of predictions:\", len(predictions_finetuned))\nprint(\"First 3 predictions:\", predictions_finetuned[:3])\n\n# 建立 submission DataFrame\nsubmission = pd.DataFrame({\n    'id': range(len(predictions_finetuned)),\n    'text': predictions_finetuned\n})\n\nprint(\"\\nSubmission shape:\", submission.shape)  # 預期 (1450, 2)\nprint(submission.head())\n\n# 輸出成 CSV\nsubmission.to_csv('submission.csv', index=False)\nprint(\"\\nSaved: submission.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T14:36:30.307541Z","iopub.execute_input":"2025-11-26T14:36:30.308179Z","iopub.status.idle":"2025-11-26T14:40:58.407710Z","shell.execute_reply.started":"2025-11-26T14:36:30.308157Z","shell.execute_reply":"2025-11-26T14:40:58.407013Z"}},"outputs":[{"name":"stdout","text":"Loaded fine-tuned model (val_loss: 0.9108351614294934)\nRunning inference on 1450 test examples...\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1450/1450 [04:27<00:00,  5.42it/s]","output_type":"stream"},{"name":"stdout","text":"\nInference finished.\nNumber of predictions: 1450\nFirst 3 predictions: ['i get tired with the song and days commit', 'here', 'you ought a mcgirr surprised']\n\nSubmission shape: (1450, 2)\n   id                                       text\n0   0  i get tired with the song and days commit\n1   1                                       here\n2   2               you ought a mcgirr surprised\n3   3               i think mamie you like it it\n4   4               hsiao that they do have prom\n\nSaved: submission.csv\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"import pandas as pd\n\nsubmission = pd.read_csv('submission.csv')\n\nprint(submission.head())\nprint(submission.tail())\nprint(submission['text'].str.len().describe())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T14:46:02.964115Z","iopub.execute_input":"2025-11-26T14:46:02.964605Z","iopub.status.idle":"2025-11-26T14:46:02.977752Z","shell.execute_reply.started":"2025-11-26T14:46:02.964585Z","shell.execute_reply":"2025-11-26T14:46:02.976975Z"}},"outputs":[{"name":"stdout","text":"   id                                       text\n0   0  i get tired with the song and days commit\n1   1                                       here\n2   2               you ought a mcgirr surprised\n3   3               i think mamie you like it it\n4   4               hsiao that they do have prom\n        id                              text\n1445  1445  gees they daane have the ill fee\n1446  1446           a lot of new sus it the\n1447  1447                   an aue a have a\n1448  1448            she wass at the aw one\n1449  1449           shire beta that is fant\ncount    1450.000000\nmean       24.041379\nstd         9.929479\nmin         1.000000\n25%        17.000000\n50%        24.000000\n75%        31.000000\nmax        64.000000\nName: text, dtype: float64\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink('submission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T15:07:11.616020Z","iopub.execute_input":"2025-11-26T15:07:11.616505Z","iopub.status.idle":"2025-11-26T15:07:11.621114Z","shell.execute_reply.started":"2025-11-26T15:07:11.616485Z","shell.execute_reply":"2025-11-26T15:07:11.620551Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/submission.csv","text/html":"<a href='submission.csv' target='_blank'>submission.csv</a><br>"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"# ============================================================\n# ENSEMBLE INFERENCE:\n#   original baseline + fine-tuned baseline (CTC)\n#   產生 submission_ensemble.csv\n# ============================================================\n\nimport os\nimport torch\nimport itertools\nimport pandas as pd\nfrom tqdm import tqdm\n\n# 1. 建兩個 model：原始 baseline + fine-tuned baseline\n\nprint(\"Loading ORIGINAL baseline model ...\")\nbaseline_model_base = BaselineGRU().to(device)\n\nBASELINE_DIR = \"/kaggle/input/brain-to-text-25/t15_pretrained_rnn_baseline/t15_pretrained_rnn_baseline\"\nckpt_base = torch.load(\n    os.path.join(BASELINE_DIR, \"checkpoint\", \"best_checkpoint\"),\n    map_location=device,\n    weights_only=False,\n)\nstate_dict_base = ckpt_base[\"model_state_dict\"]\nstate_dict_base = {k.replace(\"_orig_mod.\", \"\"): v for k, v in state_dict_base.items()}\nbaseline_model_base.load_state_dict(state_dict_base, strict=True)\nbaseline_model_base.eval()\n\nprint(\"Loading FINE-TUNED baseline model ...\")\nbaseline_model_ft = BaselineGRU().to(device)\nckpt_ft = torch.load(\"finetuned_baseline.pt\", map_location=device)\nbaseline_model_ft.load_state_dict(ckpt_ft[\"model_state_dict\"])\nbaseline_model_ft.eval()\n\nprint(\"Both models ready.\")\nprint(f\"Running ENSEMBLE inference on {len(test_data['neural_features'])} test examples...\\n\")\n\n# 2. 逐筆做 ensemble 推論\npredictions_ens = []\n\nfor i in tqdm(range(len(test_data[\"neural_features\"]))):\n    session = test_data[\"session\"][i]\n    day_idx = session_to_day.get(session, 0)\n\n    x = preproc.preprocess(\n        test_data[\"neural_features\"][i],\n        test_data[\"n_time_steps\"][i],\n    )\n    x = torch.tensor(x).unsqueeze(0).float().to(device)\n\n    with torch.no_grad():\n        # 兩個模型都算一次 logits（其實是 log-probs）\n        logits_base = baseline_model_base(x, day_idx=day_idx)\n        logits_ft = baseline_model_ft(x, day_idx=day_idx)\n\n        # 做簡單平均 ensemble\n        logits_ens = 0.5 * (logits_base + logits_ft)\n\n        preds = logits_ens.squeeze(0).argmax(-1).cpu().numpy()\n\n    # CTC: 合併重複 & 去掉 BLANK (index = 0)\n    phonemes = [PHONEMES[idx] for idx, _ in itertools.groupby(preds) if idx != 0]\n\n    text = phonemes_to_text(phonemes)\n    predictions_ens.append(text if text else \" \")\n\nprint(\"\\nInference finished.\")\nprint(\"Number of predictions:\", len(predictions_ens))\n\n# 3. 建立 submission DataFrame\nsubmission_ens = pd.DataFrame({\n    \"id\": range(len(predictions_ens)),\n    \"text\": predictions_ens,\n})\n\nprint(\"\\nSubmission shape:\", submission_ens.shape)\nprint(submission_ens.head())\n\n# 4. 存檔\nsubmission_ens.to_csv(\"submission_ensemble.csv\", index=False)\nprint(\"\\nSaved: submission_ensemble.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T14:59:23.060887Z","iopub.execute_input":"2025-11-26T14:59:23.061198Z","iopub.status.idle":"2025-11-26T15:06:52.178939Z","shell.execute_reply.started":"2025-11-26T14:59:23.061176Z","shell.execute_reply":"2025-11-26T15:06:52.178192Z"}},"outputs":[{"name":"stdout","text":"Loading ORIGINAL baseline model ...\nLoading FINE-TUNED baseline model ...\nBoth models ready.\nRunning ENSEMBLE inference on 1450 test examples...\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1450/1450 [07:27<00:00,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"\nInference finished.\nNumber of predictions: 1450\n\nSubmission shape: (1450, 2)\n   id   text\n0   0    i'd\n1   1       \n2   2   earp\n3   3  e you\n4   4    luz\n\nSaved: submission_ensemble.csv\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n# 1. 假設你的音素表像這樣\nPHONEMES = ['BLANK', 'AA', 'AE', ..., 'OY', ...]   # 全部音素排序\nnum_phonemes = len(PHONEMES)\n\n# 2. 指定稀有音素index（照你的表順序！）\nrare_idx = [PHONEMES.index(p) for p in ['AW', 'UH', 'CH', 'JH', 'OY']]\nweights = torch.ones(num_phonemes)\nfor idx in rare_idx:\n    weights[idx] = 10.0  # 測試3~10之間，看score最優\n\ncriterion = nn.CTCLoss(blank=0, zero_infinity=True, weight=weights.to(device))\n# 在訓練時: loss = criterion(logits, targets, input_lens, target_lens)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T15:22:07.031871Z","iopub.execute_input":"2025-11-26T15:22:07.032580Z","iopub.status.idle":"2025-11-26T15:22:07.051724Z","shell.execute_reply.started":"2025-11-26T15:22:07.032554Z","shell.execute_reply":"2025-11-26T15:22:07.050907Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_38/4253761358.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 2. 指定稀有音素index（照你的表順序！）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mrare_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mPHONEMES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'AW'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'UH'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CH'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'JH'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'OY'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_phonemes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrare_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_38/4253761358.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 2. 指定稀有音素index（照你的表順序！）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mrare_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mPHONEMES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'AW'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'UH'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CH'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'JH'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'OY'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_phonemes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrare_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: 'AW' is not in list"],"ename":"ValueError","evalue":"'AW' is not in list","output_type":"error"}],"execution_count":41},{"cell_type":"code","source":"augmented_data = []\nfor i, y in enumerate(train_labels):\n    if any(target in rare_idx for target in y):  # y是一個trial對應的音素列表\n        for _ in range(10):  # oversample十次\n            augmented_data.append(train_data[i])\n# 組合新訓練資料\ntrain_data = train_data + augmented_data\ntrain_labels = train_labels + [train_labels[i] for i, y in enumerate(train_labels)\n                              for target in y if any(t in rare_idx for t in y) for _ in range(10)]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T15:22:58.533965Z","iopub.execute_input":"2025-11-26T15:22:58.534471Z","iopub.status.idle":"2025-11-26T15:22:58.548638Z","shell.execute_reply.started":"2025-11-26T15:22:58.534450Z","shell.execute_reply":"2025-11-26T15:22:58.547729Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_38/2114620101.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0maugmented_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrare_idx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# y是一個trial對應的音素列表\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# oversample十次\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0maugmented_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_labels' is not defined"],"ename":"NameError","evalue":"name 'train_labels' is not defined","output_type":"error"}],"execution_count":42}]}